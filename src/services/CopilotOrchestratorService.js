/**
 * üß† COPILOT ORCHESTRATOR SERVICE - IA INTELIGENTE SIMPLE
 *
 * Orquesta el copiloto IA con prompts simples y directos
 * para generar respuestas inteligentes sin complejidad innecesaria.
 *
 * @version 4.0.0 IA INTELIGENTE SIMPLE
 */

const { copilotCacheService } = require('./CopilotCacheService');
const { copilotMemoryService } = require('./CopilotMemoryService');
const { generateWithProvider, isProviderAvailable } = require('../ai/vendors');
const logger = require('../utils/logger');

class CopilotOrchestratorService {
  async processMessage(userMessage, conversationId, agentId, workspaceId) {
    const start = Date.now();

    try {
      // 1. Verificar cache
      const cached = await copilotCacheService.getCachedResponse(userMessage, { conversationId, agentId });
      if (cached) {
        logger.info('‚úÖ Respuesta cacheada encontrada', { conversationId, agentId });
        return { ok: true, text: cached, source: 'cache' };
      }

      // 2. Crear prompt ultra simple y directo
      const simplePrompt = this.createSimplePrompt(userMessage, conversationId);
      
      // 3. Generar respuesta con IA
      let llmResponse = await generateWithProvider('llm_studio', {
        prompt: simplePrompt,
        model: 'gpt-oss-20b',
        temperature: 0.7,
        maxTokens: 200,
        workspaceId,
        conversationId
      });

      // 4. Fallback a OpenAI si LLM Studio falla
      if (!llmResponse.ok && isProviderAvailable('openai')) {
        logger.warn('LLM Studio fall√≥, aplicando fallback a OpenAI');
        llmResponse = await generateWithProvider('openai', {
          prompt: simplePrompt,
          model: 'gpt-4o-mini',
          temperature: 0.7,
          maxTokens: 200,
          workspaceId,
          conversationId
        });
      }

      if (!llmResponse.ok) {
        logger.error('‚ùå Error en generaci√≥n de respuesta IA', { error: llmResponse.message });
        return { ok: false, error: llmResponse.message || 'Error de IA' };
      }

      // 5. Procesar respuesta
      let finalResponse = llmResponse.text.trim();
      
      // Detectar y corregir respuestas problem√°ticas
      finalResponse = this.cleanResponse(finalResponse);
      
      // Si la respuesta est√° vac√≠a o es muy corta, usar respuesta por defecto
      if (!finalResponse || finalResponse.length < 5) {
        finalResponse = this.getDefaultResponse(userMessage);
      }

      // 6. Cache y memoria
      await copilotCacheService.cacheResponse(userMessage, { conversationId, agentId }, finalResponse);
      await copilotMemoryService.addToMemory(conversationId, userMessage, finalResponse);

      // 7. Log de √©xito
      const latencyMs = Date.now() - start;
      logger.info('‚úÖ Respuesta IA generada', {
        conversationId,
        agentId,
        responseLength: finalResponse.length,
        latencyMs,
        model: llmResponse.model || 'llm_studio'
      });

      return { 
        ok: true, 
        text: finalResponse, 
        model: llmResponse.model || 'llm_studio',
        usage: llmResponse.usage,
        suggestions: []
      };

    } catch (error) {
      logger.error('‚ùå Error en orquestador IA', { error: error.message });
      return { ok: false, error: error.message };
    }
  }

  /**
   * Crear prompt inteligente y contextual
   */
  createSimplePrompt(userMessage, conversationId) {
    return `Eres un asistente de atenci√≥n al cliente experto. Tu tarea es analizar el mensaje del cliente y proporcionar una respuesta √∫til y contextual.

CONTEXTO:
- Eres un asistente profesional de atenci√≥n al cliente
- Debes entender la intenci√≥n del cliente
- Responde de forma natural, emp√°tica y √∫til
- No uses meta-instrucciones ni reglas de formato
- Genera solo la respuesta directa al cliente

MENSAJE DEL CLIENTE:
"${userMessage}"

AN√ÅLISIS:
1. ¬øQu√© quiere el cliente?
2. ¬øCu√°l es la mejor respuesta?
3. ¬øC√≥mo puedo ayudarle?

RESPUESTA:`;
  }

  /**
   * Limpiar y corregir respuestas problem√°ticas del modelo
   */
  cleanResponse(response) {
    if (!response) return response;
    
    // Detectar meta-instrucciones comunes
    const metaInstructions = [
      /no uses c√≥digo markdown/i,
      /no incluyas ninguna explicaci√≥n/i,
      /solo la respuesta final/i,
      /responde en espa√±ol/i,
      /evita el lenguaje ofensivo/i,
      /mantente profesional/i,
      /luego responde/i,
      /2\)/i,
      /3\)/i
    ];
    
    // Si la respuesta contiene meta-instrucciones, usar respuesta por defecto
    const hasMetaInstructions = metaInstructions.some(pattern => pattern.test(response));
    if (hasMetaInstructions) {
      logger.warn('Meta-instrucciones detectadas en respuesta, usando respuesta por defecto', { response });
      return null; // Forzar uso de respuesta por defecto
    }
    
    // Remover comillas extra al inicio y final
    response = response.replace(/^["']+|["']+$/g, '');
    
    // Remover espacios extra
    response = response.trim();
    
    return response;
  }

  /**
   * Respuesta inteligente por defecto si la IA falla
   */
  getDefaultResponse(userMessage) {
    const text = userMessage.toLowerCase().trim();
    
    // Saludos
    if (/^(hola|buenos d√≠as|buenas|hi|hello|hey)$/.test(text)) {
      return '¬°Hola! Soy tu asistente virtual. ¬øEn qu√© puedo ayudarte hoy?';
    }
    
    // Despedidas
    if (/^(adi√≥s|chao|bye|goodbye|hasta luego|nos vemos)$/.test(text)) {
      return '¬°Que tengas un excelente d√≠a! No dudes en contactarnos si necesitas ayuda en el futuro.';
    }
    
    // Agradecimientos
    if (/^(gracias|thank you|thanks|muchas gracias)$/.test(text)) {
      return '¬°De nada! Es un placer ayudarte. ¬øHay algo m√°s en lo que pueda asistirte?';
    }
    
    // Preguntas sobre capacidad de pensamiento
    if (/puedes pensar|eres inteligente|tienes conciencia|eres real/i.test(text)) {
      return 'Soy un asistente virtual dise√±ado para ayudarte. Aunque no tengo conciencia como un humano, puedo procesar informaci√≥n y ayudarte con tus consultas de manera efectiva. ¬øEn qu√© puedo asistirte?';
    }
    
    // Preguntas sobre el nombre
    if (/como te llamas|cu√°l es tu nombre|quien eres/i.test(text)) {
      return 'Soy tu asistente virtual de atenci√≥n al cliente. Estoy aqu√≠ para ayudarte con cualquier consulta que tengas. ¬øEn qu√© puedo asistirte?';
    }
    
    // Preguntas sobre respuestas prefijadas
    if (/respuestas prefijadas|respuestas falsas|est√°s programado/i.test(text)) {
      return 'Entiendo tu preocupaci√≥n. Mi objetivo es ayudarte de la mejor manera posible. Cada respuesta que doy est√° basada en el contexto de tu mensaje. ¬øC√≥mo puedo ayudarte espec√≠ficamente con tu consulta?';
    }
    
    // Preguntas complejas o cr√≠ticas
    if (text.length > 50 || /por qu√©|explica|analiza/i.test(text)) {
      return 'Entiendo tu pregunta. Para darte la mejor respuesta posible, ¬øpodr√≠as ser m√°s espec√≠fico sobre lo que necesitas? Estoy aqu√≠ para ayudarte.';
    }
    
    // Respuesta gen√©rica para otros casos
    return 'Entiendo tu mensaje. Para ayudarte mejor, ¬øpodr√≠as proporcionarme m√°s detalles sobre lo que necesitas?';
  }
}

const copilotOrchestratorService = new CopilotOrchestratorService();

module.exports = {
  CopilotOrchestratorService,
  copilotOrchestratorService
};
