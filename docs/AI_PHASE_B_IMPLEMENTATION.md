# ü§ñ **FASE B - PROVEEDOR REAL Y SALUD**

## üìã **RESUMEN EJECUTIVO**

La **Fase B** implementa la integraci√≥n con proveedores reales de LLM (OpenAI por defecto) al orquestador de la Fase A, con healthchecks robustos, l√≠mites de seguridad, timeouts, reintentos, rate limiting y guardrails m√≠nimos. El sistema mantiene fallback a modo fake y est√° completamente listo para pruebas internas sin afectar flujos productivos.

### ‚úÖ **LOGROS COMPLETADOS**

- ‚úÖ **Wrapper OpenAI completo** con timeouts, retries y rate limiting
- ‚úÖ **Health check robusto** con verificaci√≥n de proveedores
- ‚úÖ **Clamps autom√°ticos** en configuraci√≥n con warnings
- ‚úÖ **Circuit breaker** para manejo de errores
- ‚úÖ **Rate limiting** por conversaci√≥n (6 req/min)
- ‚úÖ **Guardrails m√≠nimos** en prompts y salida
- ‚úÖ **Endpoint dry-run** para pruebas sin persistencia
- ‚úÖ **Kill switch** global con AI_ENABLED
- ‚úÖ **Logging detallado** con m√©tricas de uso y costos
- ‚úÖ **Tests exhaustivos** para todas las funcionalidades

### üéØ **OBJETIVOS CUMPLIDOS**

1. **Wrapper de proveedor**: OpenAI con timeouts y retries
2. **Health check**: Verificaci√≥n de proveedores y estado
3. **Clamps y validaci√≥n**: Configuraci√≥n autom√°tica con l√≠mites
4. **Timeouts y reintentos**: 2s timeout, 1 retry con backoff
5. **Rate limit**: 6 req/min por conversaci√≥n
6. **Guardrails**: Prompts seguros y salida sanitizada
7. **Logging**: M√©tricas completas de uso y costos
8. **Dry-run**: Endpoint para pruebas sin persistencia
9. **Kill switch**: Control global con AI_ENABLED

---

## üèóÔ∏è **ARQUITECTURA IMPLEMENTADA**

### **Estructura de Archivos**

```
src/
‚îú‚îÄ‚îÄ ai/
‚îÇ   ‚îî‚îÄ‚îÄ vendors/
‚îÇ       ‚îú‚îÄ‚îÄ index.js              # Interfaz unificada de proveedores
‚îÇ       ‚îî‚îÄ‚îÄ openai.js             # Wrapper OpenAI con guardrails
‚îú‚îÄ‚îÄ config/
‚îÇ   ‚îî‚îÄ‚îÄ aiConfig.js               # Configuraci√≥n con clamps mejorados
‚îú‚îÄ‚îÄ controllers/
‚îÇ   ‚îî‚îÄ‚îÄ AIController.js           # Health check y dry-run endpoints
‚îú‚îÄ‚îÄ routes/
‚îÇ   ‚îî‚îÄ‚îÄ ai.js                     # Rutas con validaciones extendidas
‚îú‚îÄ‚îÄ services/
‚îÇ   ‚îî‚îÄ‚îÄ AIService.js              # Orquestador con proveedor real
‚îî‚îÄ‚îÄ utils/
    ‚îú‚îÄ‚îÄ aiLogger.js               # Logger con m√©tricas de proveedores
    ‚îî‚îÄ‚îÄ contextLoader.js          # Loader optimizado (sin cambios)
```

### **Flujo de Datos Mejorado**

```
1. Configuraci√≥n IA (aiConfig.js) con clamps
   ‚Üì
2. Health Check (AIController.js) verifica proveedores
   ‚Üì
3. Orquestador IA (AIService.js) decide real vs fake
   ‚Üì
4. Wrapper OpenAI (openai.js) con guardrails
   ‚Üì
5. Rate Limiter + Circuit Breaker
   ‚Üì
6. Logging detallado (aiLogger.js)
   ‚Üì
7. Respuesta sanitizada y validada
```

---

## üîß **WRAPPER OPENAI**

### **Caracter√≠sticas Implementadas**

#### **1. Timeouts y Retries**
```javascript
const OPENAI_CONFIG = {
  timeout: 2000,        // 2 segundos
  maxRetries: 1,        // 1 reintento
  backoffMs: 250,       // Backoff exponencial
  maxTokensOut: 150,    // M√°ximo tokens de salida
  rateLimitPerMinute: 6 // Rate limit por conversaci√≥n
};
```

#### **2. Circuit Breaker**
- **Umbral**: 10% de error rate en 5 minutos
- **Ventana**: 5 minutos para reset autom√°tico
- **Estados**: Cerrado ‚Üí Abierto ‚Üí Semi-abierto
- **Logging**: Alertas cuando se abre/cierra

#### **3. Rate Limiting**
- **L√≠mite**: 6 requests por minuto por conversaci√≥n
- **Implementaci√≥n**: Map en memoria con reset autom√°tico
- **Respuesta**: Error 429 con mensaje claro

#### **4. Guardrails de Seguridad**
```javascript
// Sanitizaci√≥n de salida
function sanitizeOutput(text) {
  // Recortar a 500 caracteres m√°ximo
  // Remover HTML peligroso
  // Intentar parsear JSON si est√° presente
  // Validar contenido seguro
}
```

#### **5. Prompts con Guardrails**
```javascript
const prompt = `Eres un asistente de atenci√≥n al cliente profesional.

GUARDRAILS IMPORTANTES:
- NO inventes precios, productos o servicios espec√≠ficos
- Si falta informaci√≥n importante, pide UN SOLO dato espec√≠fico
- Mant√©n un tono profesional
- No uses lenguaje t√©cnico complejo
- S√© conciso pero completo

Contexto: ${context}
Respuesta sugerida:`;
```

---

## üè• **HEALTH CHECK ROBUSTO**

### **Endpoint: GET /api/ai/health**

#### **Respuesta Completa**
```json
{
  "success": true,
  "data": {
    "status": "healthy|degraded|disabled",
    "timestamp": "2025-01-27T10:30:00.000Z",
    "version": "1.0.0",
    "phase": "B",
    "features": {
      "config": true,
      "suggestions": true,
      "contextLoader": true,
      "logging": true,
      "fakeMode": true,
      "provider_ready": true
    },
    "providers": {
      "openai": {
        "ok": true,
        "provider": "openai",
        "model": "gpt-4o-mini",
        "limits": {
          "maxTokensOut": 150,
          "timeout": 2000,
          "maxRetries": 1
        }
      }
    },
    "environment": {
      "nodeEnv": "development",
      "aiEnabled": true,
      "openaiKey": true
    }
  }
}
```

#### **Estados de Salud**
- **healthy**: Todo funcionando correctamente
- **degraded**: IA habilitada pero proveedor con problemas
- **disabled**: AI_ENABLED=false

---

## üîí **CLAMPS Y VALIDACI√ìN**

### **Validaciones Autom√°ticas**

| Par√°metro | Rango | Clamp Autom√°tico |
|-----------|-------|------------------|
| temperature | 0.0 - 1.0 | Math.max(0, Math.min(1, value)) |
| maxTokens | 1 - 300 | Math.max(1, Math.min(300, value)) |
| maxContextMessages | 1 - 50 | Math.max(1, Math.min(50, value)) |
| maxTokensOut | 1 - 150 | Math.max(1, Math.min(150, value)) |
| timeout | 500 - 10000ms | Math.max(500, Math.min(10000, value)) |
| maxRetries | 0 - 3 | Math.max(0, Math.min(3, value)) |

### **Warnings Autom√°ticos**
```javascript
// Ejemplo de warnings generados
[
  "Temperature ajustada de 2.0 a 1.0",
  "maxTokens ajustado de 500 a 300",
  "Modelo invalid-model no soportado, usando gpt-4o-mini",
  "Proveedor invalid-provider no soportado, usando openai"
]
```

---

## üß™ **ENDPOINT DRY-RUN**

### **Endpoint: POST /api/ai/dry-run/suggest**

#### **Request**
```json
{
  "workspaceId": "ws_123",
  "conversationId": "conv_456",
  "messageId": "msg_789"
}
```

#### **Response**
```json
{
  "success": true,
  "data": {
    "ok": true,
    "suggestion_preview": "Hola, ¬øen qu√© puedo ayudarte hoy?",
    "usage": {
      "in": 150,
      "out": 25,
      "latencyMs": 1200
    },
    "warnings": [
      "Usando modo fake (proveedor no disponible)"
    ],
    "provider": "openai",
    "isReal": false
  }
}
```

#### **Warnings Detectados**
- **Latencia alta**: >2500ms
- **Modo fake**: Proveedor no disponible
- **Sugerencia larga**: >300 caracteres

---

## üìä **M√âTRICAS Y LOGGING**

### **Logs Estructurados**

#### **Request de IA**
```javascript
{
  "level": "info",
  "message": "ü§ñ IA - Iniciando operaci√≥n",
  "workspaceId": "ws_123",
  "operation": "openai_generate",
  "params": {
    "model": "gpt-4o-mini",
    "temperature": 0.3,
    "maxTokens": 150,
    "conversationId": "conv_456"
  }
}
```

#### **Respuesta Exitosa**
```javascript
{
  "level": "info",
  "message": "‚úÖ IA - Operaci√≥n exitosa",
  "workspaceId": "ws_123",
  "operation": "openai_generate",
  "success": true,
  "model": "gpt-4o-mini",
  "tokensIn": 150,
  "tokensOut": 25,
  "latencyMs": 1200,
  "costUsd": 0.001
}
```

#### **Error de Proveedor**
```javascript
{
  "level": "error",
  "message": "‚ùå IA - Error en operaci√≥n",
  "workspaceId": "ws_123",
  "operation": "openai_generate",
  "success": false,
  "error": "Rate limit exceeded",
  "errorType": "OpenAIError",
  "latencyMs": 500
}
```

### **Contador de Uso Diario**
```javascript
// Colecci√≥n: ai_usage/{workspaceId}/daily/{date}
{
  "openai_generate": 15,
  "openai_generate_gpt-4o-mini": 15,
  "lastUpdated": "2025-01-27T10:30:00.000Z"
}
```

---

## üåê **API REST EXTENDIDA**

### **Endpoints Nuevos/Mejorados**

| M√©todo | Endpoint | Descripci√≥n | Auth |
|--------|----------|-------------|------|
| GET | `/api/ai/health` | Health check con proveedores | No |
| PUT | `/api/ai/config/:workspaceId` | Config con clamps autom√°ticos | Admin |
| POST | `/api/ai/dry-run/suggest` | **NUEVO** - Prueba sin persistencia | Agent |

### **Configuraci√≥n Extendida**
```json
{
  "workspaceId": "ws_123",
  "ai_enabled": true,
  "provider": "openai",
  "defaultModel": "gpt-4o-mini",
  "escalationModel": "gpt-4o",
  "temperature": 0.3,
  "maxTokens": 150,
  "flags": {
    "suggestions": true,
    "rag": false,
    "reports": false,
    "console": false,
    "provider_ready": true
  },
  "policies": {
    "no_inventar_precios": true,
    "tono": "profesional",
    "idioma": "es"
  },
  "limits": {
    "maxContextMessages": 20,
    "maxResponseLength": 300,
    "maxLatencyMs": 5000,
    "maxTokensOut": 150,
    "timeout": 2000,
    "maxRetries": 1
  }
}
```

---

## üß™ **TESTS IMPLEMENTADOS**

### **Cobertura de Tests**

- ‚úÖ **Health Check**: Verificaci√≥n de proveedores y estados
- ‚úÖ **Configuraci√≥n**: Clamps autom√°ticos y validaciones
- ‚úÖ **Dry Run**: Generaci√≥n sin persistencia
- ‚úÖ **Rate Limiting**: L√≠mites por conversaci√≥n
- ‚úÖ **Circuit Breaker**: Manejo de errores
- ‚úÖ **Fallback**: Modo fake cuando proveedor falla
- ‚úÖ **M√©tricas**: Logging y contadores
- ‚úÖ **Seguridad**: Autenticaci√≥n y autorizaci√≥n

### **Casos de Prueba Espec√≠ficos**

1. **Health check sin OPENAI_API_KEY** ‚Üí ok=false
2. **Health check con clave v√°lida** ‚Üí ok=true
3. **Dry-run con conversaci√≥n real** ‚Üí suggestion_preview + usage
4. **Simulaci√≥n de timeout** ‚Üí retry + fallback
5. **Config fuera de rango** ‚Üí clamps aplicados + warnings
6. **Rate limit excedido** ‚Üí error 429
7. **Circuit breaker abierto** ‚Üí fallback a fake

---

## üîí **SEGURIDAD Y RESILIENCIA**

### **Kill Switch Global**
```bash
# Deshabilitar completamente el m√≥dulo IA
AI_ENABLED=false
```

### **Circuit Breaker**
- **Umbral**: 10% error rate en 5 minutos
- **Auto-reset**: Despu√©s de 5 minutos
- **Fallback**: Modo fake autom√°tico
- **Logging**: Alertas cuando se activa

### **Rate Limiting**
- **Por conversaci√≥n**: 6 req/min
- **Implementaci√≥n**: Memoria con reset autom√°tico
- **Respuesta**: Error controlado sin excepci√≥n

### **Guardrails de Contenido**
- **Sanitizaci√≥n**: HTML peligroso removido
- **Longitud**: M√°ximo 500 caracteres
- **JSON**: Parseo seguro con fallback
- **Prompts**: Reglas de seguridad integradas

---

## üöÄ **VARIABLES DE ENTORNO**

### **Configuraci√≥n Requerida**

```bash
# Habilitar m√≥dulo IA
AI_ENABLED=true

# Proveedor OpenAI
OPENAI_API_KEY=sk-...

# Configuraci√≥n opcional
AI_MODEL=gpt-4o-mini
AI_TEMPERATURE=0.3
AI_MAX_TOKENS=150
```

### **Configuraci√≥n por Workspace**
```javascript
// Habilitar proveedor real
{
  "ai_enabled": true,
  "provider": "openai",
  "flags": {
    "provider_ready": true,
    "suggestions": true
  }
}
```

---

## üìã **DEFINICI√ìN DE HECHO (DoD)**

### ‚úÖ **Criterios Cumplidos**

1. **‚úÖ /api/ai/health y /api/ai/dry-run/suggest operativos y seguros**
   - Health check verifica proveedores
   - Dry-run genera sugerencias sin persistencia
   - Ambos endpoints seguros y validados

2. **‚úÖ Clamps, timeouts, retries y rate limit verificados**
   - Configuraci√≥n con clamps autom√°ticos
   - Timeout 2s con 1 retry
   - Rate limit 6 req/min por conversaci√≥n
   - Tests exhaustivos implementados

3. **‚úÖ Guardrails activos y salida saneada**
   - Prompts con reglas de seguridad
   - Sanitizaci√≥n de salida autom√°tica
   - Validaci√≥n de contenido
   - Logging de warnings

4. **‚úÖ Provider listo para integrarse en Fase C**
   - Wrapper OpenAI completo
   - Interfaz extensible para otros proveedores
   - Fallback robusto a modo fake
   - Sin deuda t√©cnica cr√≠tica

### **Pruebas de Verificaci√≥n**

```bash
# Health check sin API key
curl http://localhost:3001/api/ai/health
# Respuesta: provider_ready=false, ok=false

# Health check con API key
curl http://localhost:3001/api/ai/health
# Respuesta: provider_ready=true, ok=true

# Dry-run con conversaci√≥n real
curl -X POST http://localhost:3001/api/ai/dry-run/suggest \
  -H "Content-Type: application/json" \
  -H "Authorization: Bearer token" \
  -H "X-User: {\"role\":\"agent\"}" \
  -d '{"workspaceId":"test","conversationId":"test","messageId":"test"}'
# Respuesta: suggestion_preview + usage + warnings

# Config con clamps
curl -X PUT http://localhost:3001/api/ai/config/test-workspace \
  -H "Authorization: Bearer token" \
  -H "X-User: {\"role\":\"admin\"}" \
  -d '{"temperature":2.0,"maxTokens":500}'
# Respuesta: temperature=1.0, maxTokens=300 (clamps aplicados)
```

---

## üîÑ **PR√ìXIMOS PASOS (FASE C)**

### **Preparaci√≥n para Fase C**

1. **Integraci√≥n con webhooks** (opcional, solo si se requiere)
2. **Chat lateral IA** con subcolecci√≥n `ai_sessions`
3. **Upload y indexaci√≥n de documentos** para RAG
4. **Eventos Socket.IO** para sugerencias en tiempo real
5. **UI de chat lateral** en el frontend
6. **Proveedores adicionales** (Anthropic, Gemini)

### **Puntos de Enganche Identificados**

- **Webhook de mensajes**: L√≠nea 320 en `MessageService.js`
- **Socket events**: Nuevos eventos `suggestion:new`, `ai:console:reply`
- **Frontend**: Panel lateral en `ConversationDetail.js`
- **Proveedores**: Interfaz en `src/ai/vendors/index.js`

---

## üìö **REFERENCIAS T√âCNICAS**

### **Archivos Principales**

- `src/ai/vendors/openai.js`: Wrapper OpenAI con guardrails
- `src/ai/vendors/index.js`: Interfaz unificada de proveedores
- `src/config/aiConfig.js`: Configuraci√≥n con clamps mejorados
- `src/controllers/AIController.js`: Health check y dry-run
- `src/services/AIService.js`: Orquestador con proveedor real
- `src/routes/ai.js`: Rutas con validaciones extendidas

### **Colecciones Firestore**

- `ai_configs/{workspaceId}`: Configuraci√≥n IA por workspace
- `ai_usage/{workspaceId}/daily/{date}`: M√©tricas de uso diario
- `suggestions/{conversationId}/suggestions/{suggestionId}`: Sugerencias (solo test-suggestion)

### **Dependencias**

- `openai`: Cliente oficial de OpenAI
- `uuid`: Generaci√≥n de IDs √∫nicos
- `joi`: Validaci√≥n de esquemas
- `firebase-admin`: Persistencia en Firestore
- `supertest`: Tests de integraci√≥n

---

## üéØ **CONCLUSI√ìN**

La **Fase B** del m√≥dulo IA ha sido implementada exitosamente, proporcionando una integraci√≥n robusta y segura con proveedores reales de LLM. El sistema mantiene fallback completo a modo fake y est√° listo para pruebas internas sin afectar flujos productivos.

**Caracter√≠sticas clave logradas:**
- ‚úÖ Integraci√≥n completa con OpenAI
- ‚úÖ Health check robusto con verificaci√≥n de proveedores
- ‚úÖ Clamps autom√°ticos con warnings
- ‚úÖ Circuit breaker y rate limiting
- ‚úÖ Guardrails de seguridad
- ‚úÖ Endpoint dry-run para pruebas
- ‚úÖ Logging detallado con m√©tricas
- ‚úÖ Tests exhaustivos
- ‚úÖ Fallback robusto a modo fake

El m√≥dulo est√° **listo para pruebas internas** y puede ser habilitado gradualmente por workspace. La arquitectura es extensible para futuros proveedores y est√° preparada para la Fase C.